{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFERRED_PREDICATE_FILE_NAME = \"SERIES.txt\"\n",
    "TRUTH_PREDICATE_FILE_NAME = \"Series_truth.txt\"\n",
    "AR_BASELINE_FILE_NAME = \"ARBaseline_obs.txt\"\n",
    "CLUSTER_BASELINE_NAME = \"ARBaselineNaiveTD_obs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\"NRMSE\", \"MASE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mase(a, f, scale):\n",
    "    return np.mean(np.abs(a - f)) / scale\n",
    "\n",
    "def smape(a, f):\n",
    "    return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_run(data_dir, result_dir, n_folds, method_name, results_df, params, eval_baseline=False, cluster_baseline=False):\n",
    "    \n",
    "    mase_scale_factors = dict()\n",
    "\n",
    "    for line in open(os.path.join(data_dir, \"mase_scale.txt\"), \"r\").readlines():\n",
    "        tokens = line.rstrip().split(\"\\t\")\n",
    "        mase_scale_factors[tokens[0]] = float(tokens[1])\n",
    "\n",
    "    stddevs = dict()\n",
    "\n",
    "    for line in open(os.path.join(data_dir, \"stddevs.txt\"), \"r\").readlines():\n",
    "        tokens = line.rstrip().split(\"\\t\")\n",
    "        stddevs[tokens[0]] = float(tokens[1])\n",
    "        \n",
    "    result_rows = []    \n",
    "    \n",
    "    for i in range(30):\n",
    "        fold_dir = str(i).zfill(3)\n",
    "        if not os.path.isdir(os.path.join(result_dir, fold_dir)):\n",
    "            continue\n",
    "\n",
    "        result_fold_dir = os.path.join(result_dir, fold_dir)\n",
    "        truth_fold_dir = os.path.join(data_dir, fold_dir)\n",
    "\n",
    "        truth_lines = open(os.path.join(truth_fold_dir, TRUTH_PREDICATE_FILE_NAME), \"r\").readlines()\n",
    "\n",
    "        if eval_baseline:\n",
    "            result_lines = open(os.path.join(truth_fold_dir, AR_BASELINE_FILE_NAME), \"r\").readlines()\n",
    "        else:\n",
    "            result_lines = open(os.path.join(result_fold_dir, INFERRED_PREDICATE_FILE_NAME), \"r\").readlines()\n",
    "\n",
    "        if cluster_baseline:\n",
    "            result_lines = open(os.path.join(truth_fold_dir, CLUSTER_BASELINE_NAME), \"r\").readlines()\n",
    "\n",
    "\n",
    "        truth_dict = dict()\n",
    "        result_dict = dict()\n",
    "        ar_baseline_dict = dict()\n",
    "\n",
    "        for line in truth_lines:\n",
    "            tokens = line.split(\"\\t\")\n",
    "            series_id = tokens[0]\n",
    "            timestep = tokens[1]\n",
    "            val = tokens[2].rstrip()\n",
    "\n",
    "            if series_id not in truth_dict:\n",
    "                truth_dict[series_id] = dict()\n",
    "\n",
    "            truth_dict[series_id][timestep] = float(val)\n",
    "\n",
    "        for line in result_lines:\n",
    "            tokens = line.split(\"\\t\")\n",
    "            series_id = tokens[0]\n",
    "            timestep = tokens[1]\n",
    "            val = tokens[2].rstrip()\n",
    "\n",
    "            if series_id not in result_dict:\n",
    "                result_dict[series_id] = dict()\n",
    "\n",
    "            result_dict[series_id][timestep] = float(val)\n",
    "\n",
    "\n",
    "        for series in truth_dict.keys():\n",
    "            abs_errors = []\n",
    "\n",
    "            sq_errors = []\n",
    "\n",
    "            truth_values = []\n",
    "            \n",
    "            predicted_values = []\n",
    "\n",
    "            for timestep in sorted(list(truth_dict[series].keys())):\n",
    "                truth_values += [truth_dict[series][timestep]]\n",
    "                predicted_values += [result_dict[series][timestep]]\n",
    "\n",
    "                ts_abs_error = np.abs(truth_dict[series][timestep] - result_dict[series][timestep])\n",
    "                abs_errors += [ts_abs_error]\n",
    "                sq_errors += [ts_abs_error ** 2]\n",
    "\n",
    "            s_mase = mase(np.array(truth_values), np.array(predicted_values), mase_scale_factors[series])\n",
    "\n",
    "            s_nrmse = np.sqrt(np.mean(sq_errors)) / stddevs[series]\n",
    "\n",
    "            result_rows += [{\"base_noise_std\": params[0], \"clus_or_std\": params[1], \"temp_or_std\": params[2], \"Series_ID\": series, \"Forecast_Window\": fold_dir, \"Method\": method_name, \"NRMSE\": s_nrmse,\n",
    "                                                              \"MASE\": s_mase}]\n",
    "\n",
    "    return pd.DataFrame(result_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating cw_hard with base noise 0\n",
      "Evaluating temporal_hard with base noise 0\n",
      "Evaluating cw_hard with base noise 0.5\n",
      "Evaluating temporal_hard with base noise 0.5\n",
      "Evaluating cw_hard with base noise 1\n",
      "Evaluating temporal_hard with base noise 1\n",
      "Evaluating cw_hard with base noise 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating temporal_hard with base noise 1.5\n",
      "Evaluating cw_hard with base noise 2\n",
      "Evaluating temporal_hard with base noise 2\n"
     ]
    }
   ],
   "source": [
    "models = [\"cw_hard\", \"temporal_hard\"]\n",
    "base_noise_stds = [0, 0.5, 1, 1.5, 2]\n",
    "n_folds = 30\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"base_noise_std\", \"clus_or_std\", \"temp_or_std\", \"Series_ID\", \"Forecast_Window\", \"Method\", \"NRMSE\", \"SMAPE\", \"MASE\"])\n",
    "\n",
    "for base_noise_std in base_noise_stds:\n",
    "    clus_or_std = 0\n",
    "    temp_or_std = 0\n",
    "    \n",
    "    for model in models:\n",
    "        print(\"Evaluating \" + model + \" with base noise \" + str(base_noise_std))\n",
    "        \n",
    "        data_dir = \"data/E1_fixednoise/base_noise_\" + str(base_noise_std) + \"/clus_or_variance_0/cross_cov_0/temp_or_variance_0/window_size_4/eval\"\n",
    "        result_dir = \"results/Online/E1_fixednoise/base_noise_\" + str(base_noise_std) + \"/clus_or_variance_0/cross_cov_0/temp_or_variance_0/window_size_4/\" + model + \"/inferred-predicates\"\n",
    "\n",
    "        results_df = pd.concat([results_df, eval_run(data_dir, result_dir, n_folds, \"PSL_\" + str(model), results_df, [base_noise_std, clus_or_std, temp_or_std])])\n",
    "        results_df = pd.concat([results_df, eval_run(data_dir, result_dir, n_folds, \"AR\", results_df, [base_noise_std, clus_or_std, temp_or_std], eval_baseline=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base_noise = 0 PSL Model: cw_hard NRMSE = 0.7112026991711417 +- 0.036120712953674874\n",
      "\n",
      "B_noise = 0 AR NRMSE = 0.708958330350146 +- 0.03738423023102443\n",
      "\n",
      "\n",
      "Base_noise = 0.5 PSL Model: cw_hard NRMSE = 0.7274134036302561 +- 0.03666813617474336\n",
      "\n",
      "B_noise = 0.5 AR NRMSE = 0.7258643502935178 +- 0.03785918622817364\n",
      "\n",
      "\n",
      "Base_noise = 1 PSL Model: cw_hard NRMSE = 0.7761551649141907 +- 0.038112709628265226\n",
      "\n",
      "B_noise = 1 AR NRMSE = 0.7755301642025221 +- 0.03898970257877851\n",
      "\n",
      "\n",
      "Base_noise = 1.5 PSL Model: cw_hard NRMSE = 0.8502352412185642 +- 0.04338907426040914\n",
      "\n",
      "B_noise = 1.5 AR NRMSE = 0.8487911435340538 +- 0.042937548902763675\n",
      "\n",
      "\n",
      "Base_noise = 2 PSL Model: cw_hard NRMSE = 0.9403340695710869 +- 0.0513364536366314\n",
      "\n",
      "B_noise = 2 AR NRMSE = 0.938994213549593 +- 0.04981251731621002\n",
      "\n",
      "\n",
      "Base_noise = 0 PSL Model: temporal_hard NRMSE = 0.7101829806561194 +- 0.03613703803719058\n",
      "\n",
      "B_noise = 0 AR NRMSE = 0.708958330350146 +- 0.03738423023102443\n",
      "\n",
      "\n",
      "Base_noise = 0.5 PSL Model: temporal_hard NRMSE = 0.7281582056524499 +- 0.03764349535171422\n",
      "\n",
      "B_noise = 0.5 AR NRMSE = 0.7258643502935178 +- 0.03785918622817364\n",
      "\n",
      "\n",
      "Base_noise = 1 PSL Model: temporal_hard NRMSE = 0.7770631910856411 +- 0.04058681385524745\n",
      "\n",
      "B_noise = 1 AR NRMSE = 0.7755301642025221 +- 0.03898970257877851\n",
      "\n",
      "\n",
      "Base_noise = 1.5 PSL Model: temporal_hard NRMSE = 0.8503289562838922 +- 0.04330633784378608\n",
      "\n",
      "B_noise = 1.5 AR NRMSE = 0.8487911435340538 +- 0.042937548902763675\n",
      "\n",
      "\n",
      "Base_noise = 2 PSL Model: temporal_hard NRMSE = 0.9413613776871099 +- 0.051797097866113584\n",
      "\n",
      "B_noise = 2 AR NRMSE = 0.938994213549593 +- 0.04981251731621002\n",
      "\n",
      "\n",
      "Base_noise = 0 PSL Model: cw_hard SMAPE = 13.40607695037223 +- 0.8943856486512934\n",
      "\n",
      "B_noise = 0 AR SMAPE = 13.325231773376972 +- 0.8434974960048683\n",
      "\n",
      "\n",
      "Base_noise = 0.5 PSL Model: cw_hard SMAPE = 12.982142510005481 +- 0.7563374790141678\n",
      "\n",
      "B_noise = 0.5 AR SMAPE = 12.960386297071334 +- 0.798305485594338\n",
      "\n",
      "\n",
      "Base_noise = 1 PSL Model: cw_hard SMAPE = 12.869239054028242 +- 0.7901552055375918\n",
      "\n",
      "B_noise = 1 AR SMAPE = 12.859785382869486 +- 0.7945508508088895\n",
      "\n",
      "\n",
      "Base_noise = 1.5 PSL Model: cw_hard SMAPE = nan +- nan\n",
      "\n",
      "B_noise = 1.5 AR SMAPE = nan +- nan\n",
      "\n",
      "\n",
      "Base_noise = 2 PSL Model: cw_hard SMAPE = 12.463228185796671 +- 0.960285692285678\n",
      "\n",
      "B_noise = 2 AR SMAPE = 12.458822211238806 +- 0.904901096704814\n",
      "\n",
      "\n",
      "Base_noise = 0 PSL Model: temporal_hard SMAPE = 13.347208053634695 +- 0.816992880681272\n",
      "\n",
      "B_noise = 0 AR SMAPE = 13.325231773376972 +- 0.8434974960048683\n",
      "\n",
      "\n",
      "Base_noise = 0.5 PSL Model: temporal_hard SMAPE = 13.026097209645997 +- 0.8301552634337832\n",
      "\n",
      "B_noise = 0.5 AR SMAPE = 12.960386297071334 +- 0.798305485594338\n",
      "\n",
      "\n",
      "Base_noise = 1 PSL Model: temporal_hard SMAPE = 12.895490369318386 +- 0.8418053882138301\n",
      "\n",
      "B_noise = 1 AR SMAPE = 12.859785382869486 +- 0.7945508508088895\n",
      "\n",
      "\n",
      "Base_noise = 1.5 PSL Model: temporal_hard SMAPE = nan +- nan\n",
      "\n",
      "B_noise = 1.5 AR SMAPE = nan +- nan\n",
      "\n",
      "\n",
      "Base_noise = 2 PSL Model: temporal_hard SMAPE = 12.4987243576875 +- 0.9359644796878276\n",
      "\n",
      "B_noise = 2 AR SMAPE = 12.458822211238806 +- 0.904901096704814\n",
      "\n",
      "\n",
      "Base_noise = 0 PSL Model: cw_hard MASE = 0.6684177414991677 +- 0.040357118673271526\n",
      "\n",
      "B_noise = 0 AR MASE = 0.6630621305455419 +- 0.040362044553763486\n",
      "\n",
      "\n",
      "Base_noise = 0.5 PSL Model: cw_hard MASE = 0.6830632182066485 +- 0.039693180493442705\n",
      "\n",
      "B_noise = 0.5 AR MASE = 0.6784726845529786 +- 0.04012269939093683\n",
      "\n",
      "\n",
      "Base_noise = 1 PSL Model: cw_hard MASE = 0.7321836708153869 +- 0.04604089337248055\n",
      "\n",
      "B_noise = 1 AR MASE = 0.7272493681881723 +- 0.04292120985658445\n",
      "\n",
      "\n",
      "Base_noise = 1.5 PSL Model: cw_hard MASE = 0.8049835322366217 +- 0.05342946171240006\n",
      "\n",
      "B_noise = 1.5 AR MASE = 0.8003789124991182 +- 0.05051220489309191\n",
      "\n",
      "\n",
      "Base_noise = 2 PSL Model: cw_hard MASE = 0.8929247043845822 +- 0.06657179446195095\n",
      "\n",
      "B_noise = 2 AR MASE = 0.8919349334766594 +- 0.05933410364700917\n",
      "\n",
      "\n",
      "Base_noise = 0 PSL Model: temporal_hard MASE = 0.6663033135781223 +- 0.039475245704627134\n",
      "\n",
      "B_noise = 0 AR MASE = 0.6630621305455419 +- 0.040362044553763486\n",
      "\n",
      "\n",
      "Base_noise = 0.5 PSL Model: temporal_hard MASE = 0.6861069461360203 +- 0.042331067899099246\n",
      "\n",
      "B_noise = 0.5 AR MASE = 0.6784726845529786 +- 0.04012269939093683\n",
      "\n",
      "\n",
      "Base_noise = 1 PSL Model: temporal_hard MASE = 0.7305187883114487 +- 0.049606252934889246\n",
      "\n",
      "B_noise = 1 AR MASE = 0.7272493681881723 +- 0.04292120985658445\n",
      "\n",
      "\n",
      "Base_noise = 1.5 PSL Model: temporal_hard MASE = 0.8029182067112924 +- 0.051440784237037046\n",
      "\n",
      "B_noise = 1.5 AR MASE = 0.8003789124991182 +- 0.05051220489309191\n",
      "\n",
      "\n",
      "Base_noise = 2 PSL Model: temporal_hard MASE = 0.8974684375149716 +- 0.06394293033015572\n",
      "\n",
      "B_noise = 2 AR MASE = 0.8919349334766594 +- 0.05933410364700917\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric in METRICS:\n",
    "    for model in models:\n",
    "        for std in base_noise_stds:\n",
    "            window_vals = []\n",
    "            ar_window_vals = []\n",
    "\n",
    "            for name, group in results_df[(results_df[\"Method\"] == \"PSL_\" + str(model)) & (results_df[\"base_noise_std\"] == std) & (results_df[\"clus_or_std\"] == 0)].groupby(by=[\"Forecast_Window\"]):\n",
    "                window_vals += [np.mean(group[metric].values)]\n",
    "            for name, group in results_df[(results_df[\"Method\"] == \"AR\") & (results_df[\"base_noise_std\"] == std) & (results_df[\"clus_or_std\"] == 0)].groupby(by=[\"Forecast_Window\"]):\n",
    "                ar_window_vals += [np.mean(group[metric].values)]\n",
    "\n",
    "            print(\"Base_noise = \" + str(std) + \" PSL Model: \" + model + \" \" + metric + \" = \" + str(np.mean(window_vals)) + \" +- \" + str(np.std(window_vals)) + \"\\n\")\n",
    "            print(\"B_noise = \" + str(std) + \" AR \" + metric + \" = \" + str(np.mean(ar_window_vals)) + \" +- \" + str(np.std(ar_window_vals)) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
